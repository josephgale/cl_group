{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6521378e-cd03-4ad0-96ca-43000689820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This program retreives policy documents for the following presidencies: \n",
    "# Bill Clinton: January 20, 1993 – January 20, 2001\n",
    "# George W. Bush January 20, 2001 – January 20, 2009\n",
    "# Barak Obama January 20, 2009 - January 20, 2017\n",
    "# Donald Trump January 20, 2017 - January 20, 2021\n",
    "\n",
    "#To create the api request link for extracting a JSON file of document links:\n",
    "#   first go to: https://www.federalregister.gov/developers/documentation/api/v1#/Federal%20Register%20Documents/get_documents__format_\n",
    "#   then go to: /documents.{format}\n",
    "\n",
    "#group csv: https://docs.google.com/spreadsheets/d/1nAUT-cp7qoj6k9heMqnCvq3aPEAWs8vi/edit#gid=560835552"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d743448-3619-4c62-9f21-82b840689031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e344f5c-157f-4b91-af0d-5d669d61ca66",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m url1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.federalregister.gov/api/v1/documents.json?fields[]=raw_text_url&per_page=1&order=oldest&conditions[publication_date][gte]=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(currentYear)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-01-01&conditions[publication_date][lte]=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(currentYear)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-06-30&conditions[type][]=RULE&conditions[sections][]=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39msection\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#this is the actual API call\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m res \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(\u001b[43murl\u001b[49m)\n\u001b[1;32m     12\u001b[0m raw_data \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#convert all data from API call to utf-8 to prevent errors\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'url' is not defined"
     ]
    }
   ],
   "source": [
    "#set up basic API to collect every 6 months staring 1995; this set up is specific to the Federal Register API \n",
    "currentYear = 1995\n",
    "section = \"environment\"\n",
    "#other section is heath-and-public-welfare\n",
    "\n",
    "#url1 is for the first half of year; url2 is for second half\n",
    "url1 = \"https://www.federalregister.gov/api/v1/documents.json?fields[]=raw_text_url&per_page=1&order=oldest&conditions[publication_date][gte]=\"+str(currentYear)+\"-01-01&conditions[publication_date][lte]=\"+str(currentYear)+\"-06-30&conditions[type][]=RULE&conditions[sections][]=\"+section\n",
    "url2 = \"https://www.federalregister.gov/api/v1/documents.json?fields[]=raw_text_url&per_page=1&order=oldest&conditions[publication_date][gte]=\"+str(currentYear)+\"-07-01&conditions[publication_date][lte]=\"+str(currentYear)+\"-12-31&conditions[type][]=RULE&conditions[sections][]=\"+section\n",
    "\n",
    "#this is the actual API call\n",
    "res = urllib.request.urlopen(url)\n",
    "raw_data = res.read()\n",
    "\n",
    "#convert all data from API call to utf-8 to prevent errors\n",
    "encoding = res.info().get_content_charset('utf8')\n",
    "data = json.loads(raw_data.decode(encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "684235da-68e7-49f1-822c-572072681fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an temp array and populate it with the utf-8 encoded urls\n",
    "urlsTempList = []\n",
    "for url in data['results']:\n",
    "    urlsTempList.append(url['raw_text_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60a5acba-92fe-4254-a696-b57e59cc41dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the temp array to create a CSV \n",
    "fields=urlsTempList\n",
    "with open(r'' + str(currentYear) + \"_\" + section, 'a') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a2258c-196a-48eb-baf0-4903884144a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: put the above procedure in a loop\n",
    "#TODO: create url for health-and-public-welfare as well\n",
    "#TODO: another program: fetch each url, extract text/agency, put ageny in var, create file name with var in it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
